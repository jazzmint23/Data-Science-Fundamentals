{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Fanchu (Jasmine) Zhou\n",
    "UID: U51496285\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Initialization\n",
    "Initial centroids: [0, 2]\n",
    "\n",
    "Step 2: Assignment\n",
    "We calculate the distance between each data point and both centroids and assign each data point to the centroid with the closest distance:\n",
    "\n",
    "Data point 0 is equidistant from both centroids [0] and [2], so we assign it to the nearest one, which is [0].\n",
    "Data point 0.5 assigned to [0].\n",
    "Data point 1.5 assigned to [2].\n",
    "Data point 2 is equidistant from both centroids [0] and [2], so we assign it to the nearest one, which is [2].\n",
    "Data point 6 is assigned to [0].\n",
    "Data point 6.5  assigned to [2].\n",
    "Data point 7 is assigned to [2].\n",
    "\n",
    "Step 3: Update\n",
    "Now, we recalculate the centroids based on the assigned data points:\n",
    "\n",
    "For centroid [0], the assigned data points are [0, 0.5, 6]. The new centroid is the average of these points: (0 + 0.5 + 6) / 3 = 2.17 (rounded to 2 decimal places).\n",
    "For centroid [2], the assigned data points are [1.5, 2, 6.5, 7]. The new centroid is the average of these points: (1.5 + 2 + 6.5 + 7) / 4 = 4 (rounded to 1 decimal place).\n",
    "\n",
    "Step 4: Repeat\n",
    "We now have updated centroids [2.17, 4]. We repeat steps 2 and 3 until convergence. Let's see if the centroids change significantly:\n",
    "\n",
    "Repeat Step 2 (Assignment):\n",
    "\n",
    "Repeat Step 3 (Update):\n",
    "\n",
    "For centroid [2.17], the assigned data points are [0, 0.5, 1.5, 2]. The new centroid is the average of these points: (0 + 0.5 + 1.5 + 2) / 4 = 1 (rounded to 1 decimal place).\n",
    "For centroid [4], the assigned data points are [6, 6.5, 7]. The new centroid is the average of these points: (6 + 6.5 + 7) / 3 = 6.5 (rounded to 1 decimal place).\n",
    "Now, the centroids are [1, 6.5]. Let's check for convergence:\n",
    "\n",
    "Repeat Step 2 (Assignment):\n",
    "\n",
    "\n",
    "Repeat Step 3 (Update):\n",
    "\n",
    "For centroid [1], the assigned data points are [0, 0.5, 1.5, 2]. The new centroid is the average of these points: (0 + 0.5 + 1.5 + 2) / 4 = 1 (no change).\n",
    "For centroid [6.5], the assigned data points are [6, 6.5, 7]. The new centroid is the average of these points: (6 + 6.5 + 7) / 3 = 6.5 (no change).\n",
    "The centroids [1, 6.5] have not changed in the last iteration, which means we have reached convergence. The final clusters are:\n",
    "\n",
    "Cluster 1: [0, 0.5, 1.5, 2]\n",
    "Cluster 2: [6, 6.5, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well the data points in our dataset are grouped into clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initial centroids can significantly impact the final clustering result. Depending on where these initial centroids are randomly placed or initialized, the algorithm may converge to different local minima.\n",
    "\n",
    "If there are outliers, K-means may try to accommodate them by positioning centroids closer to the outliers, which can affect the clustering of other data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd's Algorithm (the standard K-means algorithm) does not always guarantee convergence to the global minimum of the cost function. Whether or not it converges depends on various factors, including the initial conditions, data distribution, and specific cases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/fcz/BU Google Drive/BU_Courses/CS 506/Data-Science-Fundamentals/lecture_05/worksheet_05.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcz/BU%20Google%20Drive/BU_Courses/CS%20506/Data-Science-Fundamentals/lecture_05/worksheet_05.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/fcz/BU%20Google%20Drive/BU_Courses/CS%20506/Data-Science-Fundamentals/lecture_05/worksheet_05.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image \u001b[39mas\u001b[39;00m im\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcz/BU%20Google%20Drive/BU_Courses/CS%20506/Data-Science-Fundamentals/lecture_05/worksheet_05.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fcz/BU%20Google%20Drive/BU_Courses/CS%20506/Data-Science-Fundamentals/lecture_05/worksheet_05.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    def snap(self, centers):\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "    def distance(self, x, y):\n",
    "        return np.linalg.norm(x - y)\n",
    "    \n",
    "    def init(self):\n",
    "        return self.data[np.random.choice(range(len(self.dataset)), self.k, replace = False)]\n",
    "\n",
    "    def assign(self, centers):\n",
    "        for i in range(len(self.data)):\n",
    "            minimum = self.distance(centers[0], self.data[i])\n",
    "            self.assignment[i] = 0\n",
    "            for j in range(1, len(centers)):\n",
    "                dist = self.distance(centers[j], self.data[i])\n",
    "                if dist < minimum:\n",
    "                    minimum = dist\n",
    "                    self.assignment[i] = j\n",
    "                    \n",
    "        return\n",
    "    \n",
    "    def is_diff_clusters(self, centers, new_centers):\n",
    "        for i in range(len(centers)):\n",
    "            if self.distance(centers[i], new_centers[i]) != 0:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_centers(self):\n",
    "        for i in set(self.assignment):\n",
    "            cluster = []\n",
    "            for j in range(len(self.data)):\n",
    "                if self.assignment[j] == i:\n",
    "                    cluster.append(self.data[j])\n",
    "            centers.append(np.mean(cluster))\n",
    "        return centers\n",
    "        \n",
    "\n",
    "    def lloyds(self):\n",
    "        centers = self.init()\n",
    "        self.assign(centers)\n",
    "        self.snap(centers)\n",
    "        newCenters = self.get_centers()\n",
    "\n",
    "        while self.is_diff_clusters(centers, newCenters):\n",
    "            self.assign(newCenters)\n",
    "            centers = new_centers\n",
    "            self.snap(centers)\n",
    "            new_centers = self.get_centers()\n",
    "        return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
